{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2652857a-6c99-4888-9d61-23ef21339f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import detection\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7e2fd1-fd81-49d5-93a4-0f2c3c5b98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55d7d4b-37a1-4068-bcca-5229f5cf924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "     'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "                    'train', 'truck', 'boat', 'traffic light', 'fire', 'hydrant',\n",
    "                    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "                    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                    'keyboard', 'cell phone', 'microwave oven', 'toaster', 'sink',\n",
    "                    'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                    'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b3fd5d-cd7f-4dd7-81a3-2f3ff6891b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('/home/anwar/MedicalImaging/prisma/torch/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b3908-f219-4602-a703-cea9f45955a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35121112-17f2-43ed-8fa0-f32f90da6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssd_classes(image, results, classes_to_labels):\n",
    "    identified_classes = []\n",
    "    for image_idx in range(len(results)):\n",
    "        \n",
    "        bboxes, classes, confidences = results[image_idx]\n",
    "        for idx in range(len(bboxes)):\n",
    "            identified_classes.append(classes_to_labels[classes[idx]-1])\n",
    "    return identified_classes\n",
    "\n",
    "def get_yolo_classes(yolo_dict):\n",
    "    return list(set(yolo_dict['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13223794-4918-46a4-be82-a6606c8ade85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSD MODEL\n",
    "def detect_obj_ssd(image):\n",
    "    # define the computation device\n",
    "    device = torch.device('cpu')#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # define the image transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
    "    ssd_model.to(device)\n",
    "    ssd_model.eval()\n",
    "    utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "    transformed_image = transform(image)\n",
    "    # convert to torch tensor\n",
    "    tensor = torch.tensor(transformed_image, dtype=torch.float32)\n",
    "    # add a batch dimension\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "    # get the detection results\n",
    "    with torch.no_grad():\n",
    "        detections = ssd_model(tensor)\n",
    "    results_per_input = utils.decode_results(detections)\n",
    "    best_results_per_input = [utils.pick_best(results, 0.7) for results in results_per_input]\n",
    "    classes_to_labels = utils.get_coco_object_dictionary()\n",
    "    image_result = get_ssd_classes(image, best_results_per_input, classes_to_labels)\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd0f843-d689-4caa-b877-3695ab865dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_obj_yolo(image):\n",
    "    yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    yolo_result = yolo_model(image, size = 300)\n",
    "    yolo_dict = yolo_result.pandas().xyxy[0]\n",
    "    classes = get_yolo_classes(yolo_dict)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d7f6ae-ed4e-47a0-a306-38ba9e8f1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(model_name, image):\n",
    "    \n",
    "\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    # load the list of categories in the COCO dataset and then generate a\n",
    "    # set of bounding box colors for each class\n",
    "    # CLASSES = pickle.loads(open(args[\"labels\"], \"rb\").read())\n",
    "    COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "\n",
    "    # initialize a dictionary containing model name and its corresponding \n",
    "    # torchvision function call\n",
    "    MODELS = {\n",
    "        \"frcnn-resnet\": detection.fasterrcnn_resnet50_fpn,\n",
    "        \"frcnn-mobilenet\": detection.fasterrcnn_mobilenet_v3_large_320_fpn,\n",
    "        \"retinanet\": detection.retinanet_resnet50_fpn\n",
    "    }\n",
    "    # load the model and set it to evaluation mode\n",
    "    model = MODELS[model_name](pretrained=True, progress=True).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    # add the batch dimension, scale the raw pixel intensities to the\n",
    "    # range [0, 1], and convert the image to a floating point tensor\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    image = torch.FloatTensor(image)\n",
    "    # send the input to the device and pass the it through the network to\n",
    "    # get the detections and predictions\n",
    "    image = image.to(DEVICE)\n",
    "    detections = model(image)[0]\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57bca69-31e5-4c35-aed9-9b0bb6247046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(detections):\n",
    "    labels_to_out = []\n",
    "    for i in range(0, len(detections[\"boxes\"])):\n",
    "        confidence = detections[\"scores\"][i]\n",
    "        if confidence > 0.8:\n",
    "            idx = int(detections[\"labels\"][i])\n",
    "            label = \"{}\".format(CLASSES[idx])\n",
    "            labels_to_out.append(label)\n",
    "    return labels_to_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad8c3f2-19b4-4199-8f9a-e77e062ab0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_objects(image_path):\n",
    "    #IMAGE READ\n",
    "    image = cv2.imread(image_path)\n",
    "    # keep the original height and width for resizing of bounding boxes\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    model_choice = ['frcnn-resnet', \"frcnn-mobilenet\", \"retinanet\"]\n",
    "    detects = []\n",
    "    for x in model_choice:\n",
    "        detections = detect_object(x, image)\n",
    "        detects+=get_labels(detections)\n",
    "    detects +=detect_obj_ssd(image)\n",
    "    detects +=detect_obj_yolo(image)  \n",
    "    detects = list(set(detects))\n",
    "    return {image_path: detects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d396368-e9dc-4e81-96ba-c98c49016b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/anwar/MedicalImaging/prisma/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in /home/anwar/MedicalImaging/prisma/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in /home/anwar/MedicalImaging/prisma/torch/hub/ultralytics_yolov5_master\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "YOLOv5 ðŸš€ 2022-3-14 torch 1.10.1+cu102 CUDA:0 (Quadro P4000, 8120MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sample2.jpg': ['backpack', 'giraffe', 'zebra', 'elephant']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_objects('sample2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012fe2a-2d00-4eb6-868b-62494552e115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e773fa-0db4-43d9-902e-dee9d6d24de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1fffe-cdde-4dca-9a65-91f45cc9cd47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
